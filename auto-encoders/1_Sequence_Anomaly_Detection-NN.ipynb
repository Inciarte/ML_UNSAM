{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Very basic Auto-Encoder\n",
    "\n",
    "Based on\n",
    "https://towardsdatascience.com/a-keras-based-autoencoder-for-anomaly-detection-in-sequences-75337eaed0e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_letters =  'ABCDEF'\n",
    "second_numbers = '7890'\n",
    "last_letters = 'RSTUVWXYZ'\n",
    "\n",
    "# returns a string of the following format: [4 letters A-F][1 digit 7-0][3 letters QWOPZXML]\n",
    "def get_random_string():\n",
    "    str1 = ''.join(random.choice(first_letters) for i in range(4))\n",
    "    str2 = random.choice(second_numbers)\n",
    "    str3 = ''.join(random.choice(last_letters) for i in range(3))\n",
    "    return str1+str2+str3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADBB0WYS', 'FEAB0RTU', 'CDDD9XRX', 'DFDE8TTX', 'EACC0WSY']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 25,000 sequences of this format\n",
    "random_sequences = [get_random_string() for i in range(25000)]\n",
    "random_sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the char index that we will use to encode seqs to numbers\n",
    "char_index = '0abcdefghijklmnopqrstuvwxyz'\n",
    "char_index +='ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "char_index += '123456789'\n",
    "char_index += '().,-/+=&$?@#!*:;_[]|%‚∏è{}\\\"\\'' + ' ' +'\\\\'\n",
    "\n",
    "char_to_int = dict((c, i) for i, c in enumerate(char_index))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(char_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list(enumerate(char_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34, 15, 12, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[char_to_int[c] for c in 'Hola']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sequi/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sequi/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sequi/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sequi/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sequi/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sequi/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sequi/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sequi/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sequi/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sequi/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sequi/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sequi/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#function that convert a char seqs to numbers seqs and vice-verse\n",
    "def encode_sequence_list(seqs):\n",
    "    encoded_seqs = []\n",
    "    for seq in seqs:\n",
    "        encoded_seq = [char_to_int[c] for c in seq]\n",
    "        encoded_seqs.append(encoded_seq)\n",
    "    return pad_sequences(encoded_seqs, padding='post')\n",
    "\n",
    "def decode_sequence_list(seqs):\n",
    "    decoded_seqs = []\n",
    "    for seq in seqs:\n",
    "        decoded_seq = [int_to_char[i] for i in seq]\n",
    "        decoded_seqs.append(decoded_seq)\n",
    "    return decoded_seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADBB0WYS',\n",
       " 'FEAB0RTU',\n",
       " 'CDDD9XRX',\n",
       " 'DFDE8TTX',\n",
       " 'EACC0WSY',\n",
       " 'BBBA7UXU',\n",
       " 'ECEC8TVR',\n",
       " 'DADB9YTV',\n",
       " 'BDDD0URZ',\n",
       " 'CFDA7XSU']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some anomalies to our list\n",
    "random_sequences.extend(['XYDC2DCA', 'TXSX1ABC','RNIU4XRE','AABDXUEI','SDRAC5RF'])\n",
    "#save this to a dataframe\n",
    "seqs_ds = pd.DataFrame(random_sequences)\n",
    "# encode each string seq to an integer array [[1],[5],[67]], [[45],[76],[7]\n",
    "encoded_seqs = encode_sequence_list(random_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal data:\n",
      "['ADBB0WYS', 'FEAB0RTU', 'CDDD9XRX', 'DFDE8TTX', 'EACC0WSY']\n",
      "[[27 30 28 28  0 49 51 45]\n",
      " [32 31 27 28  0 44 46 47]\n",
      " [29 30 30 30 61 50 44 50]\n",
      " [30 32 30 31 60 46 46 50]\n",
      " [31 27 29 29  0 49 45 51]]\n"
     ]
    }
   ],
   "source": [
    "print('Normal data:')\n",
    "print(random_sequences[:5])\n",
    "print(encoded_seqs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake data:\n",
      "['XYDC2DCA', 'TXSX1ABC', 'RNIU4XRE', 'AABDXUEI', 'SDRAC5RF']\n",
      "[[50 51 30 29 54 30 29 27]\n",
      " [46 50 45 50 53 27 28 29]\n",
      " [44 40 35 47 56 50 44 31]\n",
      " [27 27 28 30 50 47 31 35]\n",
      " [45 30 44 27 29 57 44 32]]\n"
     ]
    }
   ],
   "source": [
    "print('Fake data:')\n",
    "print(random_sequences[-5:])\n",
    "print(encoded_seqs[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix everything up\n",
    "np.random.shuffle(encoded_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data and Build an Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_seqs = scaler.fit_transform(encoded_seqs)\n",
    "# Divide in train and test:\n",
    "X_train = scaled_seqs[:20000]\n",
    "X_test = scaled_seqs[20000:]\n",
    "# Observe that we are training WITH the fake data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28 27 29 31  0 50 52 50]\n",
      " [30 29 32 27 61 47 48 52]\n",
      " [28 30 32 28 61 49 45 52]\n",
      " [30 28 32 31 59 44 49 45]\n",
      " [28 32 27 31  0 51 45 52]]\n",
      "[[0.04347826 0.         0.11111111 0.17391304 0.         0.76666667\n",
      "  1.         0.92      ]\n",
      " [0.13043478 0.08333333 0.27777778 0.         1.         0.66666667\n",
      "  0.83333333 1.        ]\n",
      " [0.04347826 0.125      0.27777778 0.04347826 1.         0.73333333\n",
      "  0.70833333 1.        ]\n",
      " [0.13043478 0.04166667 0.27777778 0.17391304 0.96721311 0.56666667\n",
      "  0.875      0.72      ]\n",
      " [0.04347826 0.20833333 0.         0.17391304 0.         0.8\n",
      "  0.70833333 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_seqs[:5])\n",
    "print(scaled_seqs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1109 01:06:45.880820 140438831126016 deprecation_wrapper.py:119] From /home/sequi/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1109 01:06:45.914235 140438831126016 deprecation_wrapper.py:119] From /home/sequi/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1109 01:06:45.923120 140438831126016 deprecation_wrapper.py:119] From /home/sequi/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We define the auto-encoder NN\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "\n",
    "# Parameters for the auto-encoder\n",
    "input_dim = X_train.shape[1] # number of features (8 in this case)\n",
    "encoding_dim = 8\n",
    "hidden_dim = int(encoding_dim / 2)\n",
    "\n",
    "#  Autoencoder plot:\n",
    "#\n",
    "#    x       x\n",
    "#    x       x\n",
    "#    x   x   x\n",
    "#    x   x   x\n",
    "#    x   x   x\n",
    "#    x   x   x\n",
    "#    x       x \n",
    "#    x       x\n",
    "#    \n",
    "\n",
    "\n",
    "# Typical training features\n",
    "nb_epoch = 30\n",
    "batch_size = 128\n",
    "learning_rate = 0.1\n",
    "\n",
    "# We create the auto-encoder layer by layer:\n",
    "\n",
    "# Create first layer that receives each scaled_seq\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "# Pass it to a first layer\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "# Reduce in half the layer length (extract relevant variables)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "# One more \"latent space\" layer to sophisticate the NN\n",
    "decoder = Dense(hidden_dim, activation='relu')(encoder)\n",
    "#decoder = Dense(hidden_dim-2, activation='relu')(encoder)\n",
    "#decoder = Dense(hidden_dim, activation='relu')(encoder)\n",
    "#decoder = Dense(hidden_dim, activation='relu')(encoder)\n",
    "# Now enlarge layer to go back to entering dimension\n",
    "decoder = Dense(encoding_dim, activation='relu')(decoder)\n",
    "# Finish with the same dimension as entering\n",
    "decoder = Dense(input_dim, activation='tanh')(decoder)\n",
    "\n",
    "# Physically create the auto-encoder model\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 72        \n",
      "=================================================================\n",
      "Total params: 240\n",
      "Trainable params: 240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Drop-out:</b> Observe we are not adding drop-out for simplicity, but it is recommendable to do it. Or at least to explore it! \n",
    "\n",
    "<b>Tanh:</b>\n",
    "Yan LeCun and others argue in *Efficient BackProp* that\n",
    "\n",
    "Convergence is usually faster if the average of each input variable over the training set is close to zero. To see this, consider the extreme case where all the inputs are positive. Weights to a particular node in the first weight layer are updated by an amount proportional to Œ¥x where Œ¥ is the (scalar) error at that node and x is the input vector (see equations (5) and (10)). When all of the components of an input vector are positive, all of the updates of weights that feed into a node will have the same sign (i.e. sign(Œ¥)). As a result, these weights can only all decrease or all increase together for a given input pattern. Thus, if a weight vector must change direction it can only do so by zigzagging which is inefficient and thus very slow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 01:07:01.566585 140438831126016 deprecation_wrapper.py:119] From /home/sequi/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1109 01:07:02.732564 140438831126016 deprecation_wrapper.py:119] From /home/sequi/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W1109 01:07:02.956047 140438831126016 deprecation_wrapper.py:119] From /home/sequi/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5005 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 01:07:03.313205 140438831126016 deprecation_wrapper.py:119] From /home/sequi/.local/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W1109 01:07:03.314690 140438831126016 deprecation_wrapper.py:119] From /home/sequi/.local/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.2407 - acc: 0.2365 - val_loss: 0.0986 - val_acc: 0.7794\n",
      "Epoch 2/30\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 0.0628 - acc: 0.4330 - val_loss: 0.0472 - val_acc: 0.1804\n",
      "Epoch 3/30\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.0406 - acc: 0.1708 - val_loss: 0.0348 - val_acc: 0.1804\n",
      "Epoch 4/30\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0287 - acc: 0.1708 - val_loss: 0.0231 - val_acc: 0.1804\n",
      "Epoch 5/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0206 - acc: 0.1708 - val_loss: 0.0188 - val_acc: 0.1804\n",
      "Epoch 6/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0175 - acc: 0.1708 - val_loss: 0.0164 - val_acc: 0.1806\n",
      "Epoch 7/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0151 - acc: 0.2265 - val_loss: 0.0134 - val_acc: 0.6336\n",
      "Epoch 8/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0120 - acc: 0.7329 - val_loss: 0.0109 - val_acc: 0.7794\n",
      "Epoch 9/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0103 - acc: 0.7712 - val_loss: 0.0099 - val_acc: 0.7794\n",
      "Epoch 10/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0095 - acc: 0.7712 - val_loss: 0.0092 - val_acc: 0.7794\n",
      "Epoch 11/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0089 - acc: 0.7712 - val_loss: 0.0088 - val_acc: 0.7794\n",
      "Epoch 12/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0085 - acc: 0.7712 - val_loss: 0.0085 - val_acc: 0.7794\n",
      "Epoch 13/30\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.0081 - acc: 0.7708 - val_loss: 0.0082 - val_acc: 0.7782\n",
      "Epoch 14/30\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.0078 - acc: 0.7697 - val_loss: 0.0078 - val_acc: 0.7734\n",
      "Epoch 15/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0076 - acc: 0.7677 - val_loss: 0.0076 - val_acc: 0.7682\n",
      "Epoch 16/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0074 - acc: 0.7697 - val_loss: 0.0074 - val_acc: 0.7710\n",
      "Epoch 17/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0073 - acc: 0.7698 - val_loss: 0.0074 - val_acc: 0.7696\n",
      "Epoch 18/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0072 - acc: 0.7693 - val_loss: 0.0073 - val_acc: 0.7710\n",
      "Epoch 19/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0071 - acc: 0.7699 - val_loss: 0.0072 - val_acc: 0.7696\n",
      "Epoch 20/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0070 - acc: 0.7689 - val_loss: 0.0071 - val_acc: 0.7720\n",
      "Epoch 21/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0069 - acc: 0.7685 - val_loss: 0.0070 - val_acc: 0.7670\n",
      "Epoch 22/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0069 - acc: 0.7697 - val_loss: 0.0069 - val_acc: 0.7714\n",
      "Epoch 23/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0068 - acc: 0.7690 - val_loss: 0.0069 - val_acc: 0.7686\n",
      "Epoch 24/30\n",
      "20000/20000 [==============================] - 0s 22us/step - loss: 0.0068 - acc: 0.7679 - val_loss: 0.0069 - val_acc: 0.7716\n",
      "Epoch 25/30\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 0.0067 - acc: 0.7697 - val_loss: 0.0070 - val_acc: 0.7668\n",
      "Epoch 26/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0067 - acc: 0.7677 - val_loss: 0.0067 - val_acc: 0.7774\n",
      "Epoch 27/30\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0066 - acc: 0.7674 - val_loss: 0.0067 - val_acc: 0.7736\n",
      "Epoch 28/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0066 - acc: 0.7674 - val_loss: 0.0066 - val_acc: 0.7778\n",
      "Epoch 29/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0065 - acc: 0.7691 - val_loss: 0.0066 - val_acc: 0.7782\n",
      "Epoch 30/30\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0065 - acc: 0.7708 - val_loss: 0.0066 - val_acc: 0.7792\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', \n",
    "                    loss='mean_squared_error', \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"model_seqs2.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs',\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)\n",
    "\n",
    "history = autoencoder.fit(X_train, X_train,  # <---- THIS IS THE *KEY* LINE TO MAKE IT AUTO-ENCODER\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test, X_test),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, tensorboard]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Loss:0.006492977341264486\n"
     ]
    }
   ],
   "source": [
    "#autoencoder = load_model('model_seqs2.h5')\n",
    "print(f'Min Loss:{np.min(history[\"loss\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Error Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2282694138973218\n"
     ]
    }
   ],
   "source": [
    "#get the MSE error term\n",
    "predictions = autoencoder.predict(scaled_seqs)\n",
    "mse = np.mean(np.power(scaled_seqs - predictions, 2), axis=1)\n",
    "print('MSE:', np.quantile(mse, 0.9999)) # => the 9999% quatile - only 0.0001% have error score higher than that\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets return to the seqs_ds data set that holds all the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode all the data\n",
    "encoded_seqs = encode_sequence_list(seqs_ds.iloc[:,0])\n",
    "#scale it\n",
    "#sc = MinMaxScaler()\n",
    "scaled_data = scaler.transform(encoded_seqs)\n",
    "#test = scaler.transform(encoded_seqs)\n",
    "#predict it\n",
    "# We now run again the auto-encoder, but to see its prediciton, no to train it !\n",
    "predicted = autoencoder.predict(scaled_data)\n",
    "#get the error term\n",
    "mse = np.mean(np.power(scaled_data - predicted, 2), axis=1)\n",
    "#now add them to our data frame\n",
    "seqs_ds['MSE'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us create a function that process the sequence through the autoencoder\n",
    "# and returns the output as a sequence\n",
    "def test_autoencoder(instring):\n",
    "    t0 = [instring]\n",
    "    #print(t0)\n",
    "    t1 = np.array(encode_sequence_list(t0))\n",
    "    #print(t1)\n",
    "    t2 = scaler.transform(t1)\n",
    "    #print(t2)\n",
    "    t3 = autoencoder.predict(t2)\n",
    "    #print(t3)\n",
    "    t4 = scaler.inverse_transform(t3)\n",
    "    #print(t4)\n",
    "    t5 = decode_sequence_list(t4.astype(int))\n",
    "    #print(t5)\n",
    "    out = ''.join(t5[0])\n",
    "    mse = np.mean(np.power(t2 - t3, 2), axis=1)\n",
    "    return out, round(mse[0],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BCBB3TTT', 0.00322)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A 'good' sequence is fairly well reproduced\n",
    "test_autoencoder('CBAC8QTU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BCCBBUUV', 0.26261)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But a 'bad' sequence is not correctly reproduced because the auto-encoderhas not been trained for it\n",
    "test_autoencoder('UTAC3QAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CCDC8VVV', 0.2159)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_autoencoder('RNIU4XRE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 0.9999 threshhold:0.2282694190206696\n"
     ]
    }
   ],
   "source": [
    "# We define a threshold for 'normality' as that of 99.9% (not very politically correct...)\n",
    "mse_threshold = np.quantile(seqs_ds['MSE'], 0.9999)\n",
    "print(f'MSE 0.9999 threshhold:{mse_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we create a new column in the dataframe that tags with 1 as those 'anromal' events\n",
    "seqs_ds['MSE_Outlier'] = 0\n",
    "seqs_ds.loc[seqs_ds['MSE'] > mse_threshold, 'MSE_Outlier'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of MSE outlier:3\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many are tagged as anomalous (that is the 0.1% of 25005)\n",
    "print(f\"Num of MSE outlier:{seqs_ds['MSE_Outlier'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MSE_Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>XYDC2DCA</td>\n",
       "      <td>0.469589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25001</th>\n",
       "      <td>TXSX1ABC</td>\n",
       "      <td>0.574537</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25002</th>\n",
       "      <td>RNIU4XRE</td>\n",
       "      <td>0.215899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25003</th>\n",
       "      <td>AABDXUEI</td>\n",
       "      <td>0.150012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25004</th>\n",
       "      <td>SDRAC5RF</td>\n",
       "      <td>0.240660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0       MSE  MSE_Outlier\n",
       "25000  XYDC2DCA  0.469589            1\n",
       "25001  TXSX1ABC  0.574537            1\n",
       "25002  RNIU4XRE  0.215899            0\n",
       "25003  AABDXUEI  0.150012            0\n",
       "25004  SDRAC5RF  0.240660            1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print the 5 (we know that are) anomalous events and their tag:\n",
    "seqs_ds.iloc[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MSE_Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>XYDC2DCA</td>\n",
       "      <td>0.469589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25001</th>\n",
       "      <td>TXSX1ABC</td>\n",
       "      <td>0.574537</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25004</th>\n",
       "      <td>SDRAC5RF</td>\n",
       "      <td>0.240660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0       MSE  MSE_Outlier\n",
       "25000  XYDC2DCA  0.469589            1\n",
       "25001  TXSX1ABC  0.574537            1\n",
       "25004  SDRAC5RF  0.240660            1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For curiosity, let's see all those that are tagged as anomalous\n",
    "seqs_ds.loc[seqs_ds['MSE_Outlier'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have found the anomalous events with : \n",
    "\n",
    "<b>Unsupervised Machine Learning Auto-Encoder technique! </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Aftermath\n",
    "\n",
    "- We have added anomalous events relatively different\n",
    "- It is very important how we create our char_to_int function, since here we state that 'A' and 'B' are \"similar\", but 'a' and 'A' are \"not similar\"!\n",
    "- Hence the translation \"whatever info we are examining\" -> numbers, to then feed the NN is a crucial part of the job of recognizing 'similar' things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
